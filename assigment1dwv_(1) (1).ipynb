{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook extracts data from the Wikipedia page on **Highest-Grossing Films** and stores it in a relational database. The extracted data includes film titles, release years, directors, box office revenue, and countries of origin."
      ],
      "metadata": {
        "id": "5SAgq17xVhVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Required Libraries\n",
        "\n",
        "In this step, we import the necessary Python libraries for the task:\n",
        "- `requests`: To send HTTP requests and fetch the content of the Wikipedia page.\n",
        "- `BeautifulSoup` (from `bs4`): To parse the HTML content and extract the required data.\n",
        "- `sqlite3`: To interact with the SQLite database where we will store the extracted data."
      ],
      "metadata": {
        "id": "GoCsXTRTV8-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNs7i00Zh4S3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Fetch and Parse the Wikipedia Page\n",
        "\n",
        "In this step, we:\n",
        "1. Define the URL of the Wikipedia page containing the list of highest-grossing films.\n",
        "2. Use the `requests.get()` method to send a GET request and fetch the HTML content of the page.\n",
        "3. Parse the HTML content using `BeautifulSoup` to create a structured object (`soup`) that allows us to easily navigate and extract data from the page."
      ],
      "metadata": {
        "id": "oJ2kOS6XWXBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the Wikipedia page\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
        "\n",
        "# Send a GET request to fetch the page content\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")"
      ],
      "metadata": {
        "id": "ur-4PJOnjdR0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract Data from the Table\n",
        "\n",
        "In this step, we:\n",
        "1. Locate the HTML table containing the film data using the `soup.find()` method. The table has the class `wikitable`.\n",
        "2. Initialize an empty list (`films_data`) to store the extracted data for each film.\n",
        "3. Iterate through each row of the table (skipping the header row) using `table.find_all(\"tr\")[1:]`.\n",
        "4. For each row:\n",
        "   - Extract the film title from the `<th>` element and its nested `<a>` tag. If the title is not found, use a fallback value (`\"Unknown Title\"`).\n",
        "   - Extract the release year from the appropriate column.\n",
        "   - Follow the reference link (`href`) in the title tag to the film's individual Wikipedia page to fetch additional details (director, country, and box office revenue).\n",
        "   - Parse the reference page to locate and extract the director, country, and box office revenue.\n",
        "5. Append the extracted data as a tuple to the `films_data` list."
      ],
      "metadata": {
        "id": "rWuPWNz8Wq2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the table containing the film data\n",
        "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
        "\n",
        "films_data = []\n",
        "\n",
        "# Iterate through each row in the table\n",
        "for row in table.find_all(\"tr\")[1:]:\n",
        "    columns = row.find_all(\"td\")\n",
        "\n",
        "    # Locate the <th> element within the current row and find the <a> tag\n",
        "    title_tag = row.find(\"th\").find(\"a\") if row.find(\"th\") else None\n",
        "\n",
        "    # Check if title_tag is not None before accessing .text\n",
        "    if title_tag:\n",
        "        title = title_tag.text.strip()\n",
        "    else:\n",
        "        title = \"Unknown Title\"  # Fallback in case the title is not found\n",
        "\n",
        "    release_year = int(columns[3].text.strip())\n",
        "\n",
        "    ref_link = title_tag[\"href\"] if title_tag else None\n",
        "\n",
        "    director = \"Unknown Director\"\n",
        "    country = \"Unknown Country\"\n",
        "\n",
        "    if ref_link:\n",
        "        ref_url = f\"https://en.wikipedia.org{ref_link}\"\n",
        "        ref_response = requests.get(ref_url)\n",
        "        ref_soup = BeautifulSoup(ref_response.content, \"html.parser\")\n",
        "\n",
        "        # Locate the director information on the reference page\n",
        "        director_tag = ref_soup.find(\"th\", string=\"Directed by\")\n",
        "        if director_tag:\n",
        "            director = director_tag.find_next(\"td\").text.strip()\n",
        "\n",
        "        country_tag = ref_soup.find(\"th\", string=\"Country\") or ref_soup.find(\"th\", string=\"Countries\")\n",
        "        if country_tag:\n",
        "            country = country_tag.find_next(\"td\").text.strip()\n",
        "\n",
        "        box_office_tag = ref_soup.find(\"th\", string=\"Box office\")\n",
        "        if box_office_tag:\n",
        "            box_office = box_office_tag.find_next(\"td\").text.strip()\n",
        "\n",
        "    # Append the extracted data to the list\n",
        "    films_data.append((title, release_year, director, box_office, country))"
      ],
      "metadata": {
        "id": "oSinY8VOjhA2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Data Cleaning Functions\n",
        "\n",
        "In this step, we define helper functions to clean the extracted data:\n",
        "1. **`clean_box_office(box_office)`**:\n",
        "   - Removes currency symbols (e.g., `$`), footnotes, and non-numeric characters from the box office revenue.\n",
        "   - Converts the cleaned value to a `float` for numerical analysis. If the value is empty, it returns `None`.\n",
        "\n",
        "2. **`clean_director(director)`**:\n",
        "   - Replaces newlines and multiple spaces with a single space for consistency.\n",
        "   - Removes Wikipedia footnotes (e.g., `[1]`, `[2]`) from the director names.\n",
        "\n",
        "3. **`clean_country(country)`**:\n",
        "   - Removes Wikipedia footnotes (e.g., `[1]`, `[2]`) and newlines from the country names.\n",
        "   - Fixes specific formatting issues (e.g., replacing `\"United States China\"` with `\"United States, China\"`).\n",
        "\n",
        "It is done to ensure that the extracted data is consistent and ready for insertion into the database."
      ],
      "metadata": {
        "id": "VBq-MpWvXh_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to clean box office revenue\n",
        "def clean_box_office(box_office):\n",
        "    cleaned_value = re.sub(r\"[^\\d.]\", \"\", box_office)\n",
        "    return float(cleaned_value) if cleaned_value else None\n",
        "\n",
        "# Function to clean director names\n",
        "def clean_director(director):\n",
        "    cleaned_director = re.sub(r\"\\s+\", \" \", director.replace(\"\\n\", \", \")).strip()\n",
        "    cleaned_director = re.sub(r\"\\[\\d+\\]\", \"\", director.replace(\"\\n\", \", \")).strip()\n",
        "    return cleaned_director\n",
        "\n",
        "# Function to clean country names\n",
        "def clean_country(country):\n",
        "    cleaned_country = re.sub(r\"\\[\\d+\\]\", \"\", country.replace(\"\\n\", \", \")).strip()\n",
        "    cleaned_country = re.sub(r\"United States China\", r\"United States, China\", cleaned_country)\n",
        "    cleaned_country = re.sub(r\"United KingdomUnited States\", r\"United Kingdom, United States\", cleaned_country)\n",
        "    return cleaned_country"
      ],
      "metadata": {
        "id": "nFTh62fy3WW7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Clean and Structure the Data\n",
        "\n",
        "In this step, we:\n",
        "1. **Clean and Structure the Data**:\n",
        "   - Iterate through the `films_data` list (which contains raw extracted data).\n",
        "   - For each film, create a dictionary (`cleaned_film`) with cleaned and structured data.\n",
        "   - Append each cleaned film dictionary to the `cleaned_films` list.\n",
        "\n",
        "2. **Convert Box Office Revenue**:\n",
        "   - Convert the box office revenue from billions (e.g., `1.5`) to its full numeric value (e.g., `1,500,000,000`)."
      ],
      "metadata": {
        "id": "NYMoY078YzsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and structure the data\n",
        "cleaned_films = []\n",
        "for film in films_data:\n",
        "    cleaned_film = {\n",
        "        \"title\": film[0].strip(),  # Clean title\n",
        "        \"release_year\": int(film[1]),  # Convert release year to integer\n",
        "        \"director\": clean_director(film[2]),  # Clean director names\n",
        "        \"box_office\": clean_box_office(film[3]),  # Clean box office revenue\n",
        "        \"country\": clean_country(film[4])  # Clean country names\n",
        "    }\n",
        "    cleaned_films.append(cleaned_film)\n",
        "\n",
        "# Convert box office from billions to full numeric value\n",
        "for film in cleaned_films:\n",
        "    film[\"box_office\"] = round(film[\"box_office\"] * 1_000_000_000)  # Convert to full value"
      ],
      "metadata": {
        "id": "zZbD-Fy13gJO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Store Data in SQLite Database\n",
        "\n",
        "In this step, we:\n",
        "1. **Connect to the SQLite Database**:\n",
        "   - Use the `sqlite3` library to connect to a SQLite database file named `highest_grossing_films.db`. If the file doesn't exist, it will be created automatically.\n",
        "\n",
        "2. **Create the `films` Table**:\n",
        "   - Define a table schema with the following columns:\n",
        "     - `id`: A unique identifier for each film (auto-incremented).\n",
        "     - `title`: The title of the film (text, not null).\n",
        "     - `release_year`: The year the film was released (integer).\n",
        "     - `director`: The name(s) of the director(s) (text).\n",
        "     - `box_office`: The box office revenue (real number).\n",
        "     - `country`: The country of origin (text).\n",
        "   - If the table already exists, it will not be recreated.\n",
        "\n",
        "3. **Insert the Cleaned Data**:\n",
        "   - Iterate through the `cleaned_films` list and insert each film's data into the `films` table using parameterized queries to prevent SQL injection.\n",
        "\n",
        "4. **Commit and Close**:\n",
        "   - Commit the transaction to save the changes to the database.\n",
        "   - Close the database connection."
      ],
      "metadata": {
        "id": "cCL10lXdZNb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(\"highest_grossing_films.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create the films table (if it doesn't already exist)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS films (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    title TEXT NOT NULL,\n",
        "    release_year INTEGER,\n",
        "    director TEXT,\n",
        "    box_office REAL,\n",
        "    country TEXT\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Insert the cleaned data into the table\n",
        "for film in cleaned_films:\n",
        "    cursor.execute(\"\"\"\n",
        "    INSERT INTO films (title, release_year, director, box_office, country)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    \"\"\", (film[\"title\"], film[\"release_year\"], film[\"director\"], film[\"box_office\"], film[\"country\"]))\n",
        "\n",
        "# Commit the transaction and close the connection\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "47gykjfG8MBM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Verify Data Insertion\n",
        "\n",
        "In this step, we:\n",
        "1. **Reconnect to the Database**:\n",
        "   - Reopen the SQLite database (`highest_grossing_films.db`) to verify that the data was inserted correctly.\n",
        "\n",
        "2. **Fetch and Display Data**:\n",
        "   - Execute a `SELECT` query to retrieve all rows from the `films` table.\n",
        "   - Use `fetchall()` to fetch the results and print each row to the console.\n",
        "   - This allows us to visually inspect the data.\n",
        "\n",
        "3. **Close the Connection**:\n",
        "   - Close the database connection."
      ],
      "metadata": {
        "id": "U-MrWib5ZxsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconnect to the database\n",
        "conn = sqlite3.connect(\"highest_grossing_films.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch and display the films\n",
        "cursor.execute(\"SELECT * FROM films\")\n",
        "rows = cursor.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pr6ytzV8Yvi",
        "outputId": "1427b1dd-da15-4b0f-98b5-27dc7d7982e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'Avatar', 2009, 'James Cameron', 2923500000.0, 'United Kingdom, United States')\n",
            "(2, 'Avengers: Endgame', 2019, 'Anthony RussoJoe Russo', 2799400000.0, 'United States')\n",
            "(3, 'Avatar: The Way of Water', 2022, 'James Cameron', 2320450000.0, 'United States')\n",
            "(4, 'Titanic', 1997, 'James Cameron', 2264700000.0, 'United States')\n",
            "(5, 'Star Wars: The Force Awakens', 2015, 'J. J. Abrams', 2073000000.0, 'United States')\n",
            "(6, 'Avengers: Infinity War', 2018, 'Anthony RussoJoe Russo', 2052400000.0, 'United States')\n",
            "(7, 'Ne Zha 2', 2025, 'Jiaozi', 1982300000.0, 'China')\n",
            "(8, 'Spider-Man: No Way Home', 2021, 'Jon Watts', 1923340000.0, 'United States')\n",
            "(9, 'Inside Out 2', 2024, 'Kelsey Mann', 1699340000.0, 'United States')\n",
            "(10, 'Jurassic World', 2015, 'Colin Trevorrow', 1671400000.0, 'United States')\n",
            "(11, 'The Lion King', 2019, 'Jon Favreau', 1657500000.0, 'United States')\n",
            "(12, 'The Avengers', 2012, 'Joss Whedon', 1521400000.0, 'United States')\n",
            "(13, 'Furious 7', 2015, 'James Wan', 1515400000.0, 'United States, China')\n",
            "(14, 'Top Gun: Maverick', 2022, 'Joseph Kosinski', 1496450000.0, 'United States')\n",
            "(15, 'Frozen 2', 2019, 'Chris Buck, Jennifer Lee', 1453000000.0, 'United States')\n",
            "(16, 'Barbie', 2023, 'Greta Gerwig', 1446670000.0, 'United States, United Kingdom')\n",
            "(17, 'Avengers: Age of Ultron', 2015, 'Joss Whedon', 1405400000.0, 'United States')\n",
            "(18, 'The Super Mario Bros. Movie', 2023, 'Aaron Horvath, Michael Jelenic', 1363340000.0, 'United States')\n",
            "(19, 'Black Panther', 2018, 'Ryan Coogler', 1354000000.0, 'United States')\n",
            "(20, 'Harry Potter and the Deathly Hallows – Part 2', 2011, 'David Yates', 1342400000.0, 'United Kingdom, United States')\n",
            "(21, 'Deadpool & Wolverine', 2024, 'Shawn Levy', 1338340000.0, 'United States')\n",
            "(22, 'Star Wars: The Last Jedi', 2017, 'Rian Johnson', 1334300000.0, 'United States')\n",
            "(23, 'Jurassic World: Fallen Kingdom', 2018, 'J. A. Bayona', 1317000000.0, 'China, United States')\n",
            "(24, 'Frozen', 2013, 'Chris Buck, Jennifer Lee', 1280700000.0, 'United States')\n",
            "(25, 'Beauty and the Beast', 2017, 'Bill Condon', 1266300000.0, 'United States')\n",
            "(26, 'Incredibles 2', 2018, 'Brad Bird', 1243400000.0, 'United States')\n",
            "(27, 'The Fate of the Furious', 2017, 'F. Gary Gray', 1236500000.0, 'United States, China')\n",
            "(28, 'Iron Man 3', 2013, 'Shane Black', 1266300000.0, 'United States')\n",
            "(29, 'Minions', 2015, 'Pierre Coffin, Kyle Balda', 1159400000.0, 'United States')\n",
            "(30, 'Captain America: Civil War', 2016, 'Anthony RussoJoe Russo', 1155400000.0, 'United States')\n",
            "(31, 'Aquaman', 2018, 'James Wan', 1152700000.0, 'United States')\n",
            "(32, 'The Lord of the Rings: The Return of the King', 2003, 'Peter Jackson', 1151400000.0, 'New Zealand, Germany, United States')\n",
            "(33, 'Spider-Man: Far From Home', 2019, 'Jon Watts', 1133300000.0, 'United States')\n",
            "(34, 'Captain Marvel', 2019, 'Anna BodenRyan Fleck', 1131400000.0, 'United States')\n",
            "(35, 'Transformers: Dark of the Moon', 2011, 'Michael Bay', 1124700000.0, 'United States')\n",
            "(36, 'Skyfall', 2012, 'Sam Mendes', 1109500000.0, 'United Kingdom, United States')\n",
            "(37, 'Transformers: Age of Extinction', 2014, 'Michael Bay', 1104400000.0, 'United States')\n",
            "(38, 'The Dark Knight Rises', 2012, 'Christopher Nolan', 1115400000.0, 'United States, United Kingdom')\n",
            "(39, 'Joker', 2019, 'Todd Phillips', 1079230000.0, 'United States')\n",
            "(40, 'Star Wars: The Rise of Skywalker', 2019, 'J. J. Abrams', 1077300000.0, 'United States')\n",
            "(41, 'Toy Story 4', 2019, 'Josh Cooley', 1074300000.0, 'United States')\n",
            "(42, 'Toy Story 3', 2010, 'Lee Unkrich', 1067100000.0, 'United States')\n",
            "(43, \"Pirates of the Caribbean: Dead Man's Chest\", 2006, 'Gore Verbinski', 1066200000.0, 'United States')\n",
            "(44, 'Rogue One: A Star Wars Story', 2016, 'Gareth Edwards', 1059500000.0, 'United States')\n",
            "(45, 'Moana 2', 2024, 'David Derrick Jr., Jason Hand, Dana Ledoux Miller', 1055600000.0, 'United States')\n",
            "(46, 'Aladdin', 2019, 'Guy Ritchie', 1054600000.0, 'United States')\n",
            "(47, 'Star Wars: Episode I – The Phantom Menace', 1999, 'George Lucas', 1047340000.0, 'United States')\n",
            "(48, 'Pirates of the Caribbean: On Stranger Tides', 2011, 'Rob Marshall', 1046300000.0, 'United States')\n",
            "(49, 'Jurassic Park', 1993, 'Steven Spielberg', 1058400000.0, 'United States')\n",
            "(50, 'Despicable Me 3', 2017, 'Pierre Coffin, Kyle Balda', 1035500000.0, 'United States')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Database to JSON\n",
        "\n",
        "This Python script connects to an SQLite database, fetches film data, and exports it to a JSON file. The JSON file will be used to populate the web page."
      ],
      "metadata": {
        "id": "LhL1B5W6zIIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(\"highest_grossing_films.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch all rows from the films table\n",
        "cursor.execute(\"SELECT * FROM films\")\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Convert rows to a list of dictionaries\n",
        "films_data = []\n",
        "for row in rows:\n",
        "    films_data.append({\n",
        "        \"title\": row[1],\n",
        "        \"release_year\": row[2],\n",
        "        \"director\": row[3],\n",
        "        \"box_office\": row[4],\n",
        "        \"country\": row[5]\n",
        "    })\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open(\"data_1.json\", \"w\") as json_file:\n",
        "    json.dump(films_data, json_file, indent=4)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "ziuM9380biIB"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}